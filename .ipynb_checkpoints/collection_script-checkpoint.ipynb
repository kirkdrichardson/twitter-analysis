{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "#-*-coding:utf-8-*-\n",
    "#!/usr/bin/env python\n",
    "\n",
    "##########################################################################################################################\n",
    "# Python 2.7 // succesfully run on 2.7.12 |Anaconda 4.2.0 (64-bit)\n",
    "\n",
    "############    Function     ###############################\n",
    "# This code uses Oauth credentials to download Twitter data associated the provided hashtag parameter into an SQLite database @ the provided location\n",
    "# To make this code work for your own purposes, you will need to include your own Oauth credentials, hashtag parameter(s), and access to an SQLite database\n",
    "# Comments reveal necessary modifications\n",
    "\n",
    "############    Purpose in this repository   ################\n",
    "# This code was used to create the HT-full and HT-orig datasets used in the study \"Marketing the Mountain State: A large N study of user engagment on Twitter\"\n",
    "\n",
    "############    Acknowledgements    ########################\n",
    "# Although I have made some trivial changes, the code comes from WEIAI WAYNE XU and GREGORY SAXTON.\n",
    "# original post can be found on Weiai Wayne Xu's site: http://www.curiositybits.com/new-page-2/\n",
    "# Gregory Saxton also maintains a helpful site covering Twitter analysis using Python: http://social-metrics.org/ \n",
    "# Also, check out Gregory Saxton's tutorial of Python's pandas package on Github: /gdsaxton/PANDAS\n",
    "\n",
    "#########################################################################################################################\n",
    "\n",
    "import sys\n",
    "import urllib\n",
    "import string\n",
    "import simplejson\n",
    "import sqlite3\n",
    "\n",
    "import time\n",
    "import datetime\n",
    "from pprint import pprint\n",
    "\n",
    "import sqlalchemy\n",
    "from sqlalchemy.orm import mapper, sessionmaker\n",
    "from sqlalchemy import Column, Integer, String, ForeignKey, Text, DateTime, Float\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "from sqlalchemy import Unicode #\n",
    "from sqlalchemy import Text #\n",
    "\n",
    "from sqlalchemy import DECIMAL\n",
    "from sqlalchemy import Unicode\n",
    "\n",
    "\n",
    "from sqlalchemy.sql import join\n",
    "from types import *\n",
    "\n",
    "from datetime import datetime, date, time\n",
    "\n",
    "ids = ['%23montanamoment',] # enter your search terms // the present study uses a hashtag from the ongoing campaign of the Montana Office of Tourism\n",
    "       \n",
    "from twython import Twython\n",
    "t = Twython(app_key='################',       # replace w/ your Oauth key (https://dev.twitter.com/oauth/overview)\n",
    "    app_secret='#################################################',\n",
    "    oauth_token='################################################',\n",
    "    oauth_token_secret='#########################################')\n",
    "\n",
    "Base = declarative_base()\n",
    "\n",
    "\n",
    "class Messages(Base):\n",
    "    __tablename__ = 'hashtags'\n",
    "    \n",
    "    id = Column(Integer, primary_key=True)  \n",
    "    query = Column(String)\n",
    "    tweet_id = Column(String) \n",
    "    inserted_date = Column(DateTime)\n",
    "    truncated = Column(String)\n",
    "    language = Column(String)\n",
    "    possibly_sensitive = Column(String)  ### NEW \n",
    "    coordinates = Column(String)\n",
    "    retweeted_status = Column(String)\n",
    "    created_at_text = Column(String)  \n",
    "    created_at = Column(DateTime)\n",
    "    content = Column(Text)\n",
    "    from_user_screen_name = Column(String)\n",
    "    from_user_id = Column(String)   \n",
    "    from_user_followers_count = Column(Integer)  \n",
    "    from_user_friends_count = Column(Integer)  \n",
    "    from_user_listed_count = Column(Integer)  \n",
    "    from_user_statuses_count = Column(Integer)  \n",
    "    from_user_description = Column(String)  \n",
    "    from_user_location = Column(String)  \n",
    "    from_user_created_at = Column(String)  \n",
    "    retweet_count = Column(Integer)\n",
    "    entities_urls = Column(Unicode(255))\n",
    "    entities_urls_count = Column(Integer)        \n",
    "    entities_hashtags = Column(Unicode(255))\n",
    "    entities_hashtags_count = Column(Integer)    \n",
    "    entities_mentions = Column(Unicode(255))    \n",
    "    entities_mentions_count = Column(Integer)  \n",
    "    in_reply_to_screen_name = Column(String)    \n",
    "    in_reply_to_status_id = Column(String)  \n",
    "    source = Column(String)\n",
    "    entities_expanded_urls = Column(Unicode(255)) \n",
    "    json_output = Column(String)\n",
    "    entities_media_count = Column(Integer)\n",
    "    media_expanded_url = Column(Text) \n",
    "    media_url = Column(Text) \n",
    "    media_type = Column(Text) \n",
    "    video_link = Column(Integer)\n",
    "    photo_link = Column(Integer)\n",
    "    twitpic = Column(Integer)\n",
    "    \n",
    "    def __init__(self, query, tweet_id, inserted_date, truncated, language, possibly_sensitive, coordinates, \n",
    "    retweeted_status, created_at_text, created_at, content, \n",
    "    from_user_screen_name, from_user_id, from_user_followers_count, from_user_friends_count,   \n",
    "    from_user_listed_count, from_user_statuses_count, from_user_description,   \n",
    "    from_user_location, from_user_created_at, retweet_count, entities_urls,entities_urls_count,         \n",
    "    entities_hashtags, entities_hashtags_count,entities_mentions,entities_mentions_count, in_reply_to_screen_name, in_reply_to_status_id, source, entities_expanded_urls, json_output, \n",
    "    entities_media_count, media_expanded_url, media_url, media_type,video_link, photo_link,twitpic  \n",
    "    ):        \n",
    "        self.query = query\n",
    "        self.tweet_id = tweet_id\n",
    "        self.inserted_date = inserted_date\n",
    "        self.truncated = truncated\n",
    "        self.language = language\n",
    "        self.possibly_sensitive = possibly_sensitive\n",
    "        self.coordinates = coordinates\n",
    "        self.retweeted_status = retweeted_status\n",
    "        self.created_at_text = created_at_text\n",
    "        self.created_at = created_at \n",
    "        self.content = content\n",
    "        self.from_user_screen_name = from_user_screen_name\n",
    "        self.from_user_id = from_user_id       \n",
    "        self.from_user_followers_count = from_user_followers_count\n",
    "        self.from_user_friends_count = from_user_friends_count\n",
    "        self.from_user_listed_count = from_user_listed_count\n",
    "        self.from_user_statuses_count = from_user_statuses_count\n",
    "        self.from_user_description = from_user_description\n",
    "        self.from_user_location = from_user_location\n",
    "        self.from_user_created_at = from_user_created_at\n",
    "        self.retweet_count = retweet_count\n",
    "        self.entities_urls = entities_urls\n",
    "        self.entities_urls_count = entities_urls_count        \n",
    "        self.entities_hashtags = entities_hashtags\n",
    "        self.entities_hashtags_count = entities_hashtags_count\n",
    "        self.entities_mentions = entities_mentions\n",
    "        self.entities_mentions_count = entities_mentions_count     \n",
    "        self.in_reply_to_screen_name = in_reply_to_screen_name\n",
    "        self.in_reply_to_status_id = in_reply_to_status_id\n",
    "        self.source = source\n",
    "        self.entities_expanded_urls = entities_expanded_urls\n",
    "        self.json_output = json_output\n",
    "        self.entities_media_count = entities_media_count\n",
    "        self.media_expanded_url = media_expanded_url\n",
    "        self.media_url = media_url\n",
    "        self.media_type = media_type\n",
    "        self.video_link = video_link\n",
    "        self.photo_link = photo_link\n",
    "        self.twitpic = twitpic\n",
    "  \n",
    "\n",
    "    def __repr__(self):\n",
    "       return \"<Organization, Sender('%s', '%s')>\" % (self.from_user_screen_name,self.created_at)\n",
    "\n",
    "def get_data(kid, max_id=None):\n",
    "    try:\n",
    "        d = t.search(q=kid, count = '500', result_type = 'mixed', max_id = max_id) # lang = 'en'\n",
    "        \n",
    "    except Exception, e:\n",
    "        print \"Error reading id %s, exception: %s\" % (kid, e)\n",
    "        return None\n",
    "    print \"d.keys(): \", d.keys()   \n",
    "    print \"######## # OF STATUSES IN THIS GRAB: \", len(d['statuses'])\n",
    "    print \"max_id VALUE USED FOR THIS GRAB-->\", max_id\n",
    "    return d\n",
    "    \n",
    "def write_data(self, d):   \n",
    "\n",
    "    query = d['search_metadata']['query']\n",
    "    \n",
    "    number_on_page = len(d['statuses'])\n",
    "    ids = []\n",
    "    for entry in d['statuses']:\n",
    "        json_output = str(entry)\n",
    "        tweet_id = entry['id']\n",
    "        inserted_date = datetime.now()\n",
    "        truncated = entry['truncated']\n",
    "        language = entry['lang']\n",
    "\n",
    "        if 'possibly_sensitive' in entry:\n",
    "            possibly_sensitive= entry['possibly_sensitive']\n",
    "        else:\n",
    "            possibly_sensitive = ''\n",
    "        \n",
    "        coordinates = []\n",
    "        if 'coordinates' in entry and entry['coordinates'] != None:\n",
    "            print entry['coordinates']['coordinates']\n",
    "            for coordinate in entry['coordinates']['coordinates']:\n",
    "                print coordinate, type(coordinate)\n",
    "                coordinates.append(coordinate)\n",
    "           \n",
    "            coordinates = ', '.join(map(str, coordinates))\t\t\t\t\t\t\t\n",
    "            print type(coordinates), len(coordinates), coordinates\n",
    "        else:\n",
    "            coordinates = ''\n",
    "            \n",
    "        if 'retweeted_status' in entry:\n",
    "            retweeted_status = 'THIS IS A RETWEET --> DOUBLE-CHECK JSON'\n",
    "        else:\n",
    "            retweeted_status = ''  \n",
    "        content = entry['text']\n",
    "        content = content.replace('\\n','')         \n",
    "        \n",
    "        created_at_text = entry['created_at']     \n",
    "        created_at = datetime.strptime(created_at_text, '%a %b %d %H:%M:%S +0000 %Y')   \n",
    "        created_at2 = created_at.strftime('%Y-%m-%d %H:%M:%S')   \n",
    "    \n",
    "        from_user_screen_name = entry['user']['screen_name']\n",
    "        from_user_id = entry['user']['id'] \n",
    "        from_user_followers_count = entry['user']['followers_count']\n",
    "        from_user_friends_count = entry['user']['friends_count']   \n",
    "        from_user_listed_count = entry['user']['listed_count']\n",
    "        from_user_statuses_count = entry['user']['statuses_count'] \n",
    "        from_user_description = entry['user']['description'] \n",
    "        from_user_location = entry['user']['location'] \n",
    "        from_user_created_at = entry['user']['created_at']\n",
    "        \n",
    "        retweet_count = entry['retweet_count'] \n",
    "        \n",
    "        in_reply_to_screen_name = entry['in_reply_to_screen_name']\n",
    "        in_reply_to_status_id = entry['in_reply_to_status_id']\n",
    "        entities_urls_count = len(entry['entities']['urls'])    \n",
    "        entities_hashtags_count = len(entry['entities']['hashtags'])   \n",
    "        entities_mentions_count = len(entry['entities']['user_mentions']) \n",
    "    \n",
    "        source = entry['source']          \n",
    "        entities_urls = []\n",
    "        entities_expanded_urls = []\n",
    "        \n",
    "        for link in entry['entities']['urls']:\n",
    "            if 'url' in link:\n",
    "                url = link['url']\n",
    "                expanded_url = link['expanded_url']\n",
    "                entities_urls.append(url)\n",
    "                entities_expanded_urls.append(expanded_url)\n",
    "            else:\n",
    "                print \"No urls in entry\"\n",
    "        \n",
    "        entities_hashtags = []\n",
    "        for hashtag in entry['entities']['hashtags']:\n",
    "            if 'text' in hashtag:\n",
    "                tag = hashtag['text']\n",
    "                entities_hashtags.append(tag)\n",
    "            else:\n",
    "                print \"No hashtags in entry\"\n",
    "        \n",
    "        entities_mentions = []\n",
    "        for at in entry['entities']['user_mentions']:\n",
    "            if 'screen_name' in at:\n",
    "                mention = at['screen_name']\n",
    "                entities_mentions.append(mention)\n",
    "            else:\n",
    "                print \"No mentions in entry\"\n",
    "                \n",
    "        entities_mentions = string.join(entities_mentions, u\", \")\n",
    "        entities_hashtags = string.join(entities_hashtags, u\", \")\n",
    "        entities_urls = string.join(entities_urls, u\", \")\n",
    "        entities_expanded_urls = string.join(entities_expanded_urls, u\", \")    \n",
    "        \n",
    "        video_link = 0\n",
    "        if 'vimeo' in entities_expanded_urls or 'youtube' in entities_expanded_urls or 'youtu' in entities_expanded_urls or 'vine' in entities_expanded_urls:\n",
    "            video_link = 1\t\t\t\t\t\n",
    "            print \"FOUND A VIDEO!!!\"\n",
    "        else:\n",
    "            video_link = 0\n",
    "            \n",
    "        if 'twitpic' in entities_expanded_urls:\n",
    "            twitpic = 1\t\t\t\t\t\t\n",
    "            print \"FOUND A TWITPIC LINK!\"\n",
    "        else:\n",
    "            twitpic = 0\n",
    "        if 'twitpic' in entities_expanded_urls or 'instagram' in entities_expanded_urls or 'instagr' in entities_expanded_urls:\n",
    "            photo_link = 1\t\t\t\t\t\n",
    "            print \"FOUND A TWITPIC OR INSTAGRAM LINK!!!\"\n",
    "        else:\n",
    "            photo_link = 0\n",
    "\n",
    "       \n",
    "        entities_urls = unicode(entities_urls)\n",
    "        entities_expanded_urls = unicode(entities_expanded_urls)\n",
    "        entities_hashtags = unicode(entities_hashtags)\n",
    "        entities_mentions = unicode(entities_mentions)\n",
    "    \n",
    "        print \"urls...?....\", \n",
    "        print \"user_mentions...?....\", \n",
    "        print \"hashtags...?....\", \n",
    "        \n",
    "\n",
    "        if 'symbols' in entry['entities']:\n",
    "\t\t    print \"HERE ARE THE SYMBOLS.......\", \n",
    "        else:\n",
    "\t\t    print \"THERE AIN'T NO entry['entities']['symbols']\"\n",
    "\t\t\n",
    "        if 'media' in entry['entities']:\n",
    "\t\t\tprint \"HERE ARE THE MEDIA.......\", #entry['entities']['media']\n",
    "\t\t\tentities_media_count = len(entry['entities']['media'])   \n",
    "        else:\n",
    "            entities_media_count = ''\n",
    "        \n",
    "\n",
    "        if 'media' in entry['entities']:\n",
    "            if 'expanded_url' in entry['entities']['media'][0]:\n",
    "\t\t        media_expanded_url = entry['entities']['media'][0]['expanded_url']\n",
    "            else:\n",
    "                print \"THERE AIN'T NO expanded_url in entry['entities']['media']\"\n",
    "                media_expanded_url = ''\n",
    "\t\t\t\t\t    \n",
    "            if 'media_url' in entry['entities']['media'][0]:\n",
    "\t\t        media_url = entry['entities']['media'][0]['media_url']\n",
    "            else:\n",
    "\t\t        print \"THERE AIN'T NO media_url in entry['entities']['media']\"\n",
    "\t\t        media_url = ''\n",
    "\t\t\t\t\t    \n",
    "            if 'type' in entry['entities']['media'][0]:\n",
    "\t\t        media_type = entry['entities']['media'][0]['type']\n",
    "            else:\n",
    "\t\t        print \"THERE AIN'T NO type in entry['entities']['media']\"\n",
    "\t\t        media_type = ''\n",
    "        else:\n",
    "\t\t    media_type = ''\n",
    "\t\t    media_url = ''\n",
    "\t\t    media_expanded_url = ''\n",
    "\n",
    "\n",
    "      \n",
    "        updates = self.session.query(Messages).filter_by(query=query, from_user_screen_name=from_user_screen_name,\n",
    "                content=content).all() \n",
    "        if not updates:\n",
    "            print \"inserting, query:\", query                   \n",
    "                    \n",
    "            upd = Messages(query, tweet_id, inserted_date, truncated, language, possibly_sensitive, \n",
    "                coordinates, retweeted_status, created_at_text, \n",
    "                created_at, content, from_user_screen_name, from_user_id, from_user_followers_count, \n",
    "                from_user_friends_count, from_user_listed_count, from_user_statuses_count, from_user_description,   \n",
    "                from_user_location, from_user_created_at, retweet_count, entities_urls, entities_urls_count,         \n",
    "                entities_hashtags, entities_hashtags_count, entities_mentions,entities_mentions_count, in_reply_to_screen_name, in_reply_to_status_id, source, entities_expanded_urls, json_output, \n",
    "                entities_media_count, media_expanded_url, media_url, media_type,video_link, photo_link,twitpic\n",
    "                )\n",
    "            self.session.add(upd)\n",
    "      \n",
    "                \n",
    "        else:\n",
    "            if len(updates) > 1:\n",
    "                print \"Warning: more than one update matching to_user=%s, text=%s\"\\\n",
    "                        % (to_user, content)\n",
    "            else:\n",
    "                print \"Not inserting, dupe..\"\n",
    "        \n",
    "        self.session.commit()\n",
    "        \n",
    "      \n",
    "\n",
    "class Scrape:\n",
    "    def __init__(self):    \n",
    "        engine = sqlalchemy.create_engine(\"##############################################\", echo=False)  # path of the SQLite database\n",
    "        Session = sessionmaker(bind=engine)\n",
    "        self.session = Session()  \n",
    "        Base.metadata.create_all(engine)\n",
    "\n",
    "\n",
    "    def main(self):\n",
    "        for n, kid in enumerate(ids):\n",
    "            print \"\\rprocessing id %s/%s\" % (n+1, len(ids)),\n",
    "            sys.stdout.flush()\n",
    "\n",
    "\n",
    "            d = get_data(kid)\n",
    "            if not d:\n",
    "                continue\t \n",
    "            \n",
    "            if len(d['statuses'])==0:\n",
    "                print \"THERE WERE NO STATUSES RETURNED........MOVING TO NEXT ID\"\n",
    "                continue\n",
    "                \n",
    "            write_data(self, d) \n",
    "\n",
    "            self.session.commit() \n",
    "                    \n",
    "            last_status = d['statuses'][-1]\n",
    "            min_id = last_status['id']\n",
    "            \n",
    "            max_id = min_id-1        \n",
    "            print 'THIS IS THE min_id IN THE CURRENT SET OF TWEETS: ', max_id\n",
    "           \n",
    "            if len(d['statuses']) >1:\n",
    "          \n",
    "                print \"THERE WAS AT LEAST 1 STATUS ON THE FIRST PAGE! NOW MOVING TO GRAB EARLIER TWEETS\"\n",
    "              \n",
    "                count = 2\n",
    "                while count < 40:\n",
    "                    print \"------XXXXXX------ STARTING PAGE\", count\n",
    "                    d = get_data(kid, max_id)\n",
    "                    \n",
    "                    if not d:\n",
    "                        break\n",
    "                    elif not d['statuses']:\n",
    "                        \n",
    "                        break\t\n",
    "                    \n",
    "                    last_status = d['statuses'][-1]\n",
    "                    min_id = last_status['id']\n",
    "                \n",
    "                  \n",
    "                    max_id = min_id-1\n",
    "                    print 'THIS IS THE min_id IN THE CURRENT SET OF TWEETS: ', max_id\n",
    "                   \n",
    "                    \n",
    "                    if not d:\n",
    "                        continue\t       \n",
    "\n",
    "                    write_data(self, d) \n",
    "                    self.session.commit()\n",
    "                    \n",
    "                    print \"------XXXXXX------ FINISHED WITH PAGE\", len(d['statuses']), count\n",
    "                    if not len(d['statuses']) > 0:\n",
    "    \n",
    "                        print \"--------------> WE'VE REACHED THE LAST PAGE!!!! MOVING TO NEXT ID\"\n",
    "                        break                    \n",
    "                    count += 1\n",
    "                    if count >40:\n",
    "                        print \"WE'RE AT PAGE 40!!!!!\"\n",
    "                        break\n",
    "            self.session.commit()\n",
    "\n",
    "\n",
    "        self.session.close()\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    s = Scrape()\n",
    "    s.main()\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
